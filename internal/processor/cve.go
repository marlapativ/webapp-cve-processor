package processor

import (
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"path/filepath"
	"strings"
	"sync"
	"time"

	"github.com/csye7125-su24-team06/webapp-cve-processor/internal/models"
	"github.com/csye7125-su24-team06/webapp-cve-processor/internal/repository"
	"github.com/csye7125-su24-team06/webapp-cve-processor/internal/util"
	"github.com/zhyee/zipstream"
)

type cveProcessor struct {
	repository repository.CveRepository
}

func NewCveProcessor(repository repository.CveRepository) CveProcessor {
	return &cveProcessor{
		repository: repository,
	}
}

func (p *cveProcessor) Process(url string) {
	out := make(chan *[]byte)
	wg := p.startRoutines(out)
	zipStream, err := download(url)
	if err != nil {
		panic(fmt.Sprintf("Cve zip file download failed : %v", err))
	}

	if err := processZipStream(zipStream, out); err != nil {
		panic(fmt.Sprintf("Cve zip file processing failed : %v", err))
	}
	wg.Wait()
}

func (p *cveProcessor) startRoutines(out chan *[]byte) *sync.WaitGroup {
	var wg sync.WaitGroup
	db := make(chan *models.Cve)
	wg.Add(2)
	go func(queue chan *[]byte, db chan *models.Cve) {
		defer wg.Done()
		deserializeCve(out, db)
	}(out, db)
	go func(db chan *models.Cve, repository repository.CveRepository) {
		defer wg.Done()
		bulkInsertCve(db, repository)
	}(db, p.repository)
	return &wg
}

func download(url string) (*io.ReadCloser, error) {
	resp, err := http.Get(url)
	if err != nil {
		return nil, err
	}
	return &resp.Body, nil
}

func bulkInsertCve(db chan *models.Cve, repository repository.CveRepository) {
	batchSize := repository.GetDefaultBatchSize();
	timeInit := time.Now()
	var counter int = 0
	var dbSlice []models.Cve = make([]models.Cve, 0, batchSize)
	for elem := range db {
		// If the slice is full, insert the data into the database.
		if(len(dbSlice) == batchSize) {
			counter++
			repository.BulkInsertCve(dbSlice)
			dbSlice = make([]models.Cve, 0, batchSize)
			fmt.Printf("Inserted records: %v. Time taken: %v\n", counter * batchSize, time.Since(timeInit).Seconds())
		}

		// Append the element to the slice.
		dbSlice = append(dbSlice, *elem)
	}

	// Process the remaining elements.
	if(len(dbSlice) > 0) {
		repository.BulkInsertCve(dbSlice)
		fmt.Printf("Inserted records: %v. Time taken: %v\n", 
			counter * batchSize + len(dbSlice),
			time.Since(timeInit).Seconds())
	}
}

func processZipStream(zipStream *io.ReadCloser, out chan *[]byte) error {
	zr := zipstream.NewReader(*zipStream)
	for {
		e, err := zr.GetNextEntry()
		if err == io.EOF {
			break
		}
		if err != nil {
			log.Fatalf("unable to get next entry: %s", err)
		}
		if e.IsDir() || 
			filepath.Ext(e.Name) != ".json" || 
			strings.HasSuffix(e.Name, "delta.json") || 
			strings.HasSuffix(e.Name, "deltaLog.json") {
			continue
		}

		// Read the file from the zip archive.
		srcFile, err := e.Open()
		data, err := io.ReadAll(srcFile)
		if err != nil {
			return err
		}
		srcFile.Close()
		out <- &data
	}

	close(out)
	(*zipStream).Close()
	return nil
}

func deserializeCve(queue chan *[]byte, db chan *models.Cve) {
	for elem := range queue {
        cve, err := parseCve(*elem)
		elem = nil
		if(err != nil) {
			panic(fmt.Sprintf("Cve deserialization failed %v", err))
		}
		db <- cve
    }

	// Close the database channel.
	close(db)
}

type cveMetadata struct {
	Cve_id        string `json:"cveId"`
	DateUpdated   string `json:"dateUpdated"`
	DatePublished string `json:"datePublished"`
}

type cveJson struct {
	CveMetaData cveMetadata     `json:"cveMetadata"`
	RawData     []byte			`json:"others"`
}

func parseCve(data []byte) (*models.Cve, error) {
	var cve cveJson
	if err := json.Unmarshal(data, &cve); err != nil {
		return nil, err
	}

	updated := cve.CveMetaData.DateUpdated
	if len(updated) == 0 {
		updated = cve.CveMetaData.DatePublished
	}

	result, err := util.ParseTime(updated);
	if err != nil {
		return nil, err
	}

	cveModel := models.Cve{
		Cve_id:      cve.CveMetaData.Cve_id,
		DateUpdated: result,
		Data:        data,
	}

	return &cveModel, nil
}
