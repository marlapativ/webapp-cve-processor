package processor

import (
	"archive/zip"
	"encoding/json"
	"fmt"
	"io"
	"path/filepath"
	"strings"
	"sync"
	"time"

	"github.com/csye7125-su24-team06/webapp-cve-processor/internal/models"
	"github.com/csye7125-su24-team06/webapp-cve-processor/internal/repository"
	"github.com/csye7125-su24-team06/webapp-cve-processor/internal/util"
)

type cveProcessor struct {
	repository repository.CveRepository
}

func NewCveProcessor(repository repository.CveRepository) CveProcessor {
	return &cveProcessor{
		repository: repository,
	}
}

func (p *cveProcessor) Process(zipFilePath string) {
	out := make(chan *[]byte)
	db := make(chan *models.Cve)
	var wg sync.WaitGroup
	wg.Add(2)
	go func(queue chan *[]byte, db chan *models.Cve) {
		defer wg.Done()
		deserializeCve(out, db)
	}(out, db)
	go func(db chan *models.Cve, repository repository.CveRepository) {
		defer wg.Done()
		bulkInsertCve(db, repository)
	}(db, p.repository)

	if err := processZip(zipFilePath, out); err != nil {
		panic(fmt.Sprintf("Cve zip file processing failed : %v", err))
	}
	wg.Wait()
}

func bulkInsertCve(db chan *models.Cve, repository repository.CveRepository) {
	batchSize := repository.GetDefaultBatchSize();
	timeInit := time.Now()
	var counter int = 0
	var dbSlice []models.Cve = make([]models.Cve, 0, batchSize)
	for elem := range db {
		// If the slice is full, insert the data into the database.
		if(len(dbSlice) == batchSize) {
			counter++
			repository.BulkInsertCve(dbSlice)
			dbSlice = make([]models.Cve, 0, batchSize)
			fmt.Printf("Inserted records: %v. Time taken: %v\n", counter * batchSize, time.Since(timeInit).Seconds())
		}

		// Append the element to the slice.
		dbSlice = append(dbSlice, *elem)
	}

	// Process the remaining elements.
	if(len(dbSlice) > 0) {
		repository.BulkInsertCve(dbSlice)
		fmt.Printf("Inserted records: %v. Time taken: %v\n", 
			counter * batchSize + len(dbSlice),
			time.Since(timeInit).Seconds())
	}
}

func processZip(zipFilePath string, out chan *[]byte) error {
	r, err := zip.OpenReader(zipFilePath)
	if err != nil {
		return err
	}
	defer r.Close()

	for _, f := range r.File {
		// Skip directories.
		// Skip non-json files
		// Skip delta, deltaLog files.
		if f.FileInfo().IsDir() || 
			filepath.Ext(f.Name) != ".json" || 
			strings.HasSuffix(f.Name, "delta.json") || 
			strings.HasSuffix(f.Name, "deltaLog.json") {
			continue
		}

		// Read the file from the zip archive.
		srcFile, err := f.Open()
		data, err := io.ReadAll(srcFile)
		srcFile.Close()

		out <- &data

		if err != nil {
			return err
		}
	}

	close(out)
	return nil
}

func deserializeCve(queue chan *[]byte, db chan *models.Cve) {
	for elem := range queue {
        cve, err := parseCve(*elem)
		elem = nil
		if(err != nil) {
			panic(fmt.Sprintf("Cve deserialization failed %v", err))
		}
		db <- cve
    }

	// Close the database channel.
	close(db)
}

type cveMetadata struct {
	Cve_id        string `json:"cveId"`
	DateUpdated   string `json:"dateUpdated"`
	DatePublished string `json:"datePublished"`
}

type cveJson struct {
	CveMetaData cveMetadata     `json:"cveMetadata"`
	RawData     []byte			`json:"others"`
}

func parseCve(data []byte) (*models.Cve, error) {
	var cve cveJson
	if err := json.Unmarshal(data, &cve); err != nil {
		return nil, err
	}

	updated := cve.CveMetaData.DateUpdated
	if len(updated) == 0 {
		updated = cve.CveMetaData.DatePublished
	}

	result, err := util.ParseTime(updated);
	if err != nil {
		return nil, err
	}

	cveModel := models.Cve{
		Cve_id:      cve.CveMetaData.Cve_id,
		DateUpdated: result,
		Data:        data,
	}

	return &cveModel, nil
}
